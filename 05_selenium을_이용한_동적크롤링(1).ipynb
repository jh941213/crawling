{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jh941213/crawling/blob/main/05_selenium%E1%84%8B%E1%85%B3%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB_%E1%84%83%E1%85%A9%E1%86%BC%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8F%E1%85%B3%E1%84%85%E1%85%A9%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1i7pyLvcyBE"
      },
      "source": [
        "# 국민청원 데이터 가져오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfsh9ZG71HLJ"
      },
      "source": [
        "셀레니움 , 그는 웹테스팅을 위해 만들어진 존재\n",
        "* 강점\n",
        "1) 브라우저를 직접 실행하는 기능\n",
        "-> 브라우저로 접근할 수 있는 페이지는 다 접근 가능하다\n",
        "\n",
        "2) 브라우저에서 마우스와 키보드 컨트롤 기능\n",
        "-> 마우스로 클릭할 수 있다 \n",
        "\t-> 해당 태그를 파싱할 수 있다\n",
        "\t-> 페이지의 이동이 자유롭다\n",
        "\n",
        "* 약점\n",
        "- 웹드라이버 프로그램을 설치해야 한다.\n",
        "- 불안정하다.\n",
        "- 느리다.\n",
        "\n",
        "\n",
        "* 사전지식\n",
        "- selenium에서는 tag를 element라고 명명한다.\n",
        "- selenium에서는 원하는 element를 xpath를 이용해 찾으면 된다.\n",
        "    -> 수식어 == xpath(그 외는 무시) ; == 족보+속성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftYybXggcudF"
      },
      "source": [
        "\n",
        "- 참고:\n",
        "  - [국민청원 데이터셋 CSV](https://newhiwoong.github.io/%EA%B5%AD%EB%AF%BC%EC%B2%AD%EC%9B%90/%EA%B5%AD%EB%AF%BC%EC%B2%AD%EC%9B%90-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B)\n",
        "  - [청와대 국민청원 https://www1.president.go.kr/petitions](https://www1.president.go.kr/petitions)\n",
        "  - [Using Selenium with Google Colaboratory https://darektidwell.com/using-selenium-with-google-colaboratory/](https://darektidwell.com/using-selenium-with-google-colaboratory/)\n",
        "  - [https://stackoverflow.com/questions/56829470/selenium-google-colab-error-chromedriver-executable-needs-to-be-in-path](https://stackoverflow.com/questions/56829470/selenium-google-colab-error-chromedriver-executable-needs-to-be-in-path)\n",
        " \n",
        "- 참고링크 중 \"국민청원 데이터셋 CSV\"의 내용을 토대로 수정하여 작성\n",
        "- 1건당 1-2초(google colab에서 더 느림, 실 사용은 로컬을 권장함)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7Bh5kPddKKx"
      },
      "source": [
        "## 확인된 에러의 경우 \n",
        "1. 없는 페이지\n",
        "2. 관리자 차단 페이지"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "//*[@id=\"content\"]/table/tbody/tr/td[3]/div/strong\n",
        "//*[@id=\"content\"]/table/tbody/tr[4]/td[3]/div/strong"
      ],
      "metadata": {
        "id": "vpxDdT8VGU4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7v_K1bAgNtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b45810-1004-4d3c-b918-7dfc37c03395"
      },
      "source": [
        "# install chromium, its driver, and selenium\n",
        "if 'google.colab' in sys.modules:\n",
        "    !apt-get update\n",
        "    !apt install chromium-chromedriver\n",
        "    !cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "    !pip install selenium"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Wa\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [3 In\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [80.8 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [950 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,830 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,486 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [883 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,690 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,264 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [916 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,129 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n",
            "Get:29 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:30 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n",
            "Fetched 15.6 MB in 4s (3,997 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 82 not upgraded.\n",
            "Need to get 88.3 MB of archives.\n",
            "After this operation, 294 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 99.0.4844.84-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 99.0.4844.84-0ubuntu0.18.04.1 [77.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 99.0.4844.84-0ubuntu0.18.04.1 [4,397 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 99.0.4844.84-0ubuntu0.18.04.1 [5,092 kB]\n",
            "Fetched 88.3 MB in 4s (21.7 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (99.0.4844.84-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (99.0.4844.84-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_99.0.4844.84-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (99.0.4844.84-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_99.0.4844.84-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (99.0.4844.84-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (99.0.4844.84-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (99.0.4844.84-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (99.0.4844.84-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (99.0.4844.84-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n",
            "\u001b[K     |████████████████████████████████| 968 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 43.6 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 43.4 MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 42.6 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-36.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEk-iQVejmDn"
      },
      "source": [
        "import sys\n",
        "\n",
        "# set options to be headless, ..\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "if 'ipykernel' in sys.modules:\n",
        "    from tqdm.notebook import tqdm\n",
        "else:\n",
        "    from tqdm import tqdm\n",
        "    \n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue63QSAXIddm"
      },
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "petition_info = {'pet_id':[], 'progress':[], 'title':[],  'like':[],\n",
        "                'contents':[], 'answer':[], 'category':[],\n",
        "                'sday':[], 'eday':[], 'proponent':[]}"
      ],
      "metadata": {
        "id": "AyOGrT4OQYCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rtn = []\n",
        "wd = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "pet_id = 604660\n",
        "\n",
        "url='https://www1.president.go.kr/petitions/' + str(pet_id)\n",
        "wd.get(url) # 비교 : resp = requests.get(url)\n",
        "element = WebDriverWait(wd, 3).until(EC.presence_of_element_located((By.CLASS_NAME, 'petitionsView_title')))\n",
        "# time.sleep(3) # 명시적 대기 -> 쓰지 말기\n",
        "\n",
        "# select => find_element_by_xpath, find_elements_by_xpath\n",
        "progress = wd.find_element_by_xpath('//*[@id=\"cont_view\"]/div[2]/div[1]/div/div[1]/div/div[1]/h4').text\n",
        "title = wd.find_element_by_xpath('//*[@id=\"cont_view\"]/div[2]/div[1]/div/div[1]/div/h3').text\n",
        "like = wd.find_element_by_xpath('//*[@id=\"cont_view\"]/div[2]/div[1]/div/div[1]/div/h2/span').text\n",
        "\n",
        "if progress == '답변완료':\n",
        "    contents = wd.find_element_by_xpath('//*[@id=\"cont_view\"]/div[2]/div[1]/div/div[1]/div/div[4]/div[4]').text\n",
        "\n",
        "    answer = wd.find_element_by_xpath('//*[@id=\"cont_view\"]/div[2]/div[1]/div/div[1]/div/div[5]/div').text\n",
        "else:\n",
        "    contents = wd.find_element_by_xpath('//*[@id=\"cont_view\"]/div[2]/div[1]/div/div[1]/div/div[4]/div[2]').text\n",
        "\n",
        "    answer = ''\n",
        "\n",
        "info = wd.find_element_by_xpath('//*[@id=\"cont_view\"]/div[2]/div[1]/div/div[1]/div/div[2]').text.split('\\n')\n",
        "category = info[1]\n",
        "sday = info[3]\n",
        "eday = info[5]\n",
        "proponent = info[7]\n",
        "\n",
        "info_list = [pet_id, progress, title, like, contents, answer, category, sday, eday, proponent]\n",
        "\n",
        "for k, i in zip(petition_info.keys(), info_list):\n",
        "    petition_info[k].append(i)\n",
        "petition_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcoXWRhMOjkl",
        "outputId": "b8f4058f-6e88-43d1-cbb2-c3ad79d36a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pet_id 604660\n",
            "progress 청원진행중\n",
            "title 윤석열 당선자의 대장동 부산저축은행 부실수사 봐주기 의혹과 김건희의 주가조작 실체의 진상조사 확인을 위한 청원입니다.\n",
            "like 521,315\n",
            "contents 20대 대통령으로 윤석열 후보가 당선되었습니다.\n",
            "\n",
            "그러나 여전히 본인과 그부인에 대한 의혹은 좀처럼 사라지지 않고 있습니다.\n",
            "\n",
            "대통령 후보라면 그 친가족 검증에 있어서는 먼지털 하나라도 검증대상입니다.\n",
            "\n",
            "여전히 의혹만 있을뿐 이에 대한 검증과 수사가 제대로 이루어지지 않은 상태에서 당선인 신분이 된 것은 전혀\n",
            "\n",
            "납득이 안될 일입니다.\n",
            "\n",
            "윤석열 당선인이 진정 국민과 나라를 위해 일할 지도자가 된다면 최소 이정도는 당선인 신분에도 확실한 검증이\n",
            "\n",
            "필요합니다.\n",
            "\n",
            "이것이 과연 윤석열 당선인이 외쳤던 공정과 상식입니까?\n",
            "\n",
            "도저히 국민의 한사람으로써 납득이 안될 일입니다.\n",
            "\n",
            "물론 대장동 특검에 있어서는 여당에서 대선후에도 강력추진하겠다란 의지는 확고합니다.\n",
            "\n",
            "그러나 여전히 이부분에 대해서 윤석열 당선인은 제대로된 답변과 언급이 없는 상태로 그냥 당선되면 없어진다.\n",
            "\n",
            "하는 스스로의 망각된 생각을 가진 자가 20대 대통령이 된다는거 국민의 한사람으로서 도저히 납득이 안되고 이해\n",
            "\n",
            "불가입니다.\n",
            "\n",
            "윤석열 당선인의 부산저축은행 부실수사 의혹과 김건희씨의 주가조작 의혹에 대해 당선인 신분에 있어서도 강력한\n",
            "\n",
            "수사가 이루어져야 할 것이며, 필요시 이에대한 법적제재를 받는 것, 특히나 당선자 역시국민중 한사람이라는 명분\n",
            "\n",
            "잊어서는 안될 것입니다.\n",
            "\n",
            "안될 것입니다.\n",
            "answer \n",
            "category 정치개혁\n",
            "sday 2022-03-11\n",
            "eday 2022-04-10\n",
            "proponent kakao - ***\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': ['', ''],\n",
              " 'category': ['정치개혁', '정치개혁'],\n",
              " 'contents': ['20대 대통령으로 윤석열 후보가 당선되었습니다.\\n\\n그러나 여전히 본인과 그부인에 대한 의혹은 좀처럼 사라지지 않고 있습니다.\\n\\n대통령 후보라면 그 친가족 검증에 있어서는 먼지털 하나라도 검증대상입니다.\\n\\n여전히 의혹만 있을뿐 이에 대한 검증과 수사가 제대로 이루어지지 않은 상태에서 당선인 신분이 된 것은 전혀\\n\\n납득이 안될 일입니다.\\n\\n윤석열 당선인이 진정 국민과 나라를 위해 일할 지도자가 된다면 최소 이정도는 당선인 신분에도 확실한 검증이\\n\\n필요합니다.\\n\\n이것이 과연 윤석열 당선인이 외쳤던 공정과 상식입니까?\\n\\n도저히 국민의 한사람으로써 납득이 안될 일입니다.\\n\\n물론 대장동 특검에 있어서는 여당에서 대선후에도 강력추진하겠다란 의지는 확고합니다.\\n\\n그러나 여전히 이부분에 대해서 윤석열 당선인은 제대로된 답변과 언급이 없는 상태로 그냥 당선되면 없어진다.\\n\\n하는 스스로의 망각된 생각을 가진 자가 20대 대통령이 된다는거 국민의 한사람으로서 도저히 납득이 안되고 이해\\n\\n불가입니다.\\n\\n윤석열 당선인의 부산저축은행 부실수사 의혹과 김건희씨의 주가조작 의혹에 대해 당선인 신분에 있어서도 강력한\\n\\n수사가 이루어져야 할 것이며, 필요시 이에대한 법적제재를 받는 것, 특히나 당선자 역시국민중 한사람이라는 명분\\n\\n잊어서는 안될 것입니다.\\n\\n안될 것입니다.',\n",
              "  '20대 대통령으로 윤석열 후보가 당선되었습니다.\\n\\n그러나 여전히 본인과 그부인에 대한 의혹은 좀처럼 사라지지 않고 있습니다.\\n\\n대통령 후보라면 그 친가족 검증에 있어서는 먼지털 하나라도 검증대상입니다.\\n\\n여전히 의혹만 있을뿐 이에 대한 검증과 수사가 제대로 이루어지지 않은 상태에서 당선인 신분이 된 것은 전혀\\n\\n납득이 안될 일입니다.\\n\\n윤석열 당선인이 진정 국민과 나라를 위해 일할 지도자가 된다면 최소 이정도는 당선인 신분에도 확실한 검증이\\n\\n필요합니다.\\n\\n이것이 과연 윤석열 당선인이 외쳤던 공정과 상식입니까?\\n\\n도저히 국민의 한사람으로써 납득이 안될 일입니다.\\n\\n물론 대장동 특검에 있어서는 여당에서 대선후에도 강력추진하겠다란 의지는 확고합니다.\\n\\n그러나 여전히 이부분에 대해서 윤석열 당선인은 제대로된 답변과 언급이 없는 상태로 그냥 당선되면 없어진다.\\n\\n하는 스스로의 망각된 생각을 가진 자가 20대 대통령이 된다는거 국민의 한사람으로서 도저히 납득이 안되고 이해\\n\\n불가입니다.\\n\\n윤석열 당선인의 부산저축은행 부실수사 의혹과 김건희씨의 주가조작 의혹에 대해 당선인 신분에 있어서도 강력한\\n\\n수사가 이루어져야 할 것이며, 필요시 이에대한 법적제재를 받는 것, 특히나 당선자 역시국민중 한사람이라는 명분\\n\\n잊어서는 안될 것입니다.\\n\\n안될 것입니다.'],\n",
              " 'eday': ['2022-04-10', '2022-04-10'],\n",
              " 'like': ['521,311', '521,315'],\n",
              " 'pet_id': [604660, 604660],\n",
              " 'progress': ['청원진행중', '청원진행중'],\n",
              " 'proponent': ['kakao - ***', 'kakao - ***'],\n",
              " 'sday': ['2022-03-11', '2022-03-11'],\n",
              " 'title': ['윤석열 당선자의 대장동 부산저축은행 부실수사 봐주기 의혹과 김건희의 주가조작 실체의 진상조사 확인을 위한 청원입니다.',\n",
              "  '윤석열 당선자의 대장동 부산저축은행 부실수사 봐주기 의혹과 김건희의 주가조작 실체의 진상조사 확인을 위한 청원입니다.']}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCJSH1rtXH9Y"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}